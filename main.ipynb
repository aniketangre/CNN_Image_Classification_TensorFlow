{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image classification using Convolutional Neural Networks\n",
    "\n",
    "import numpy as np\n",
    "import os \n",
    "import scipy.ndimage\n",
    "import scipy.misc as smc\n",
    "import cv2\n",
    "import tensorflow.compat.v1 as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_functions import *\n",
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Data set paths \n",
    "    results_path = \"result\"\n",
    "    train_dir = \"Train_set\"\n",
    "    test_dir  = \"Test_set\"\n",
    "    \n",
    "    # Find out input parameters\n",
    "    n_train_img, n_test_img = input_data(train_dir, test_dir)\n",
    "    img_size   = (244,244)\n",
    "    img_pixels = img_size[0]*img_size[1]\n",
    "    n_classes  = 2\n",
    "    \n",
    "    # Load training and testing data\n",
    "    train_X, train_y, test_X, test_y = load_data(train_dir, test_dir, n_train_img, n_test_img,\n",
    "                                                 n_classes, img_pixels, img_size, imgcolor = True)\n",
    "    \n",
    "    # Define architecture\n",
    "    input_nodes = img_pixels\n",
    "    print(\"Number of input nodes  : \", input_nodes)\n",
    "    hidden_nodes = 300\n",
    "    print(\"Number of hidden nodes : \", hidden_nodes)\n",
    "    n_epoch = 20\n",
    "    print(\"Number of epochs       : \", n_epoch)\n",
    "    batch_size = 128\n",
    "    print(\"Size of batch          : \", batch_size)\n",
    "    drop_rate = 0.5\n",
    "    print(\"Drop rate              : \", drop_rate)\n",
    "    \n",
    "    # Define placeholders\n",
    "    tf.disable_eager_execution()\n",
    "    x = tf.placeholder('float', [None, img_pixels])\n",
    "    \n",
    "    # Reshape input to a tensor \n",
    "    input_layer = tf.reshape(x, [-1, img_size[0], img_size[1], 1])\n",
    "\n",
    "    # Conv layer 1\n",
    "    conv1 = tf.layers.conv2d(inputs = input_layer, filters = 32, kernel_size = [3, 3], \n",
    "                             strides = 1, padding = \"same\", activation = tf.nn.relu)\n",
    "    print(\"Size of 1st convolution layer : \", conv1.shape)\n",
    "    \n",
    "    # batchN = tf.nn.batch_normalization()\n",
    "\n",
    "    # Pool layer 1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs = conv1, pool_size = [2, 2], strides = 2)\n",
    "    print(\"Size of 1st pooling layer     : \", pool1.shape)\n",
    "\n",
    "    # Conv layer 2\n",
    "    conv2 = tf.layers.conv2d(inputs = pool1, filters = 32, kernel_size = [3, 3],\n",
    "                             strides = 1, padding = \"same\", activation = tf.nn.relu)\n",
    "    print(\"Size of 2nd convolution layer : \", conv2.shape)\n",
    "\n",
    "    # Pool layer 2\n",
    "    pool2 = tf.layers.max_pooling2d(inputs = conv2, pool_size = [2, 2], strides = 2)\n",
    "    print(\"Size of 2nd pooling layer     : \", pool2.shape)\n",
    "\n",
    "    # Conv Layer 3 \n",
    "    conv3 = tf.layers.conv2d(inputs = pool2, filters = 32, kernel_size = [3, 3],\n",
    "                             strides = 1, padding = \"same\", activation = tf.nn.relu)\n",
    "    print(\"Size of 3rd convolution layer : \", conv3.shape)\n",
    "\n",
    "    # Pool layer 3\n",
    "    pool3 = tf.layers.max_pooling2d(inputs = conv3, pool_size=[2, 2], strides = 2)\n",
    "    print(\"Size of 3rd pooling layer     : \", pool3.shape)\n",
    "\n",
    "    # Conv layer 4\n",
    "    conv4 = tf.layers.conv2d(inputs = pool3, filters = 32, kernel_size = [3, 3],\n",
    "                             strides = 1, padding = \"same\", activation = tf.nn.relu)\n",
    "    print(\"Size of 4rth convolution layer: \", conv4.shape)\n",
    "\n",
    "    # Pool layer 4\n",
    "    pool4 = tf.layers.max_pooling2d(inputs = conv4, pool_size = [2, 2], strides = 2)\n",
    "    print(\"Size of 4rth pooling layer    : \", pool4.shape)\n",
    "    \n",
    "    # Fully connected layer 1\n",
    "    pool4_flat = tf.reshape(pool4, [-1, pool4.shape[1]*pool4.shape[2]*32])\n",
    "    fc = tf.layers.dense(inputs = pool4_flat, units = hidden_nodes, activation = tf.nn.relu)\n",
    "    print(\"Size of fully connected layer : \", fc.shape)\n",
    "    \n",
    "    # Dropout layer\n",
    "    dropout = tf.layers.dropout(inputs = fc, rate = drop_rate)\n",
    "    print(\"Size of dropout layer         : \", fc.shape)\n",
    "    \n",
    "    # Logits layer : input to the softmax for prediction\n",
    "    predict = tf.layers.dense(inputs = dropout, units = n_classes)\n",
    "\n",
    "    # Placeholder for labels of the classes\n",
    "    y_ = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "    # Loss function : with Softmax \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = predict, labels = y_))\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    # Create session\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # Trainig model \n",
    "    for epoch in range(n_epoch):\n",
    "        epoch_loss = 0\n",
    "        for i in range(int(n_train_img/batch_size)):\n",
    "            epoch_X, epoch_y = rand_batch(batch_size, train_X, train_y)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: epoch_X, y_: epoch_y})\n",
    "            epoch_loss += c\n",
    "        \n",
    "        pred_correct = tf.equal(tf.argmax(predict, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(pred_correct, 'float'))\n",
    "        \n",
    "        # Print important values \n",
    "        print(epoch,'from', n_epoch, 'loss value:',epoch_loss)\n",
    "        print('Accuracy:',accuracy.eval({x:test_X, y_:test_y})*100, \"%\\n------------------------------------------\")\n",
    "\n",
    "        # Save predictions and labels to a csv file for analysis\n",
    "        prediction = tf.argmax(predict,1)\n",
    "        p =  prediction.eval(feed_dict={x: test_X}, session=sess)\n",
    "        np.savetxt(results_path + \"/results.csv\", np.r_['0,2', np.argmax(test_y, axis=1), p], delimiter = \",\")\n",
    "\n",
    "    # Save the trained model \n",
    "    saver.save(sess, results_path + \"/trained_model\")\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
